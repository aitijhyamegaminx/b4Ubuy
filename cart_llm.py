
# -*- coding: utf-8 -*-
"""B4UBuy.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wUGPTWPOSN-FRTFCNjPoEzVVjeKJzqlk
"""

#only to be run the first time (after that no need to run this)
import pandas as pd
import numpy as np
import os
from pathlib import Path

# Resolve file paths relative to this module so relative CWDs won't break imports
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
CATEGORIZED_CSV = os.path.join(BASE_DIR, 'openfoodfacts_categorized.csv')
PRECOMPUTED_CSV = os.path.join(BASE_DIR, 'openfoodfacts_precomputed.csv')

# Load dataset (confirmed columns from your CSV)
if not Path(CATEGORIZED_CSV).exists():
    raise FileNotFoundError(f"Required CSV not found: {CATEGORIZED_CSV}")
df = pd.read_csv(CATEGORIZED_CSV)

# Your exact nutrient columns
NUTRICOLS = ['energy-kcal_value', 'fat_value', 'saturated-fat_value', 'carbohydrates_value',
             'sugars_value', 'fiber_value', 'proteins_value', 'sodium_value']

# Your exact personas
personas = ["standard", "diabetic", "hypertension", "bodybuilder", "vegan", "vegetarian",
            "eggetarian", "jain", "pregnancy", "lactating", "elderly"]

# Your exact persona weights
weights = {
    "standard": {'proteins_value': 0.6, 'fiber_value': 0.4, 'sugars_value': -0.6, 'sodium_value': -0.4},
    "diabetic": {'sugars_value': -1.0, 'fiber_value': 0.6, 'proteins_value': 0.3},
    "hypertension": {'sodium_value': -1.0, 'fiber_value': 0.4, 'proteins_value': 0.3, 'saturated-fat_value': -0.3},
    "bodybuilder": {'proteins_value': 1.0, 'fiber_value': 0.5, 'sodium_value': -0.5, 'sugars_value': -0.3},
    "vegan": {'proteins_value': 0.7, 'fiber_value': 0.5, 'sugars_value': -0.4},
    "vegetarian": {'proteins_value': 0.7, 'fiber_value': 0.5, 'sugars_value': -0.4},
    "eggetarian": {'proteins_value': 0.7, 'fiber_value': 0.5, 'sugars_value': -0.4},
    "jain": {'proteins_value': 0.7, 'fiber_value': 0.5, 'sugars_value': -0.4},
    "pregnancy": {'proteins_value': 0.8, 'fiber_value': 0.5, 'sodium_value': -0.7, 'sugars_value': -0.6},
    "lactating": {'proteins_value': 0.7, 'fiber_value': 0.5, 'sugars_value': -0.5, 'sodium_value': -0.4},
    "elderly": {'proteins_value': 0.5, 'fiber_value': 0.4, 'sodium_value': -0.8, 'sugars_value': -0.5}
}

print("Precomputing health scores for all 11 personas (~3min)...")
for persona in personas:
    print(f"   {persona}...")

    w = weights[persona]
    scores = []  # FIXED: Initialize list outside loop

    for _, row in df.iterrows():
        score = 0.0
        weight_sum = 0.0

        for col, weight in w.items():
            val = row.get(col, 0)
            if pd.notna(val):
                weight_sum += abs(weight)
                if weight < 0:  # Penalty
                    score += weight * -val
                else:  # Bonus
                    score += weight * val

        if weight_sum < 1e-3:
            nova = row.get('off_nova_groups', 1)
            if pd.notna(nova):
                score = 0.2 - (nova - 1) * 0.3  # NOVA fallback
            else:
                score = 0.0
            weight_sum = 1.0

        norm_score = np.clip(score / max(weight_sum, 10.0), -1.0, 1.0)
        scores.append(norm_score)  # FIXED: Append to list

    # Assign scores (your exact bug fix)
    df[f'health_score_{persona}'] = scores
    df[f'health_label_{persona}'] = ['green' if s >= 0.25 else 'amber' if s >= -0.25 else 'red' for s in scores]

    # Nutrient completeness for confidence (your logic)
    completeness = df[NUTRICOLS].notna().sum(axis=1) / len(NUTRICOLS)
    df[f'health_confidence_{persona}'] = ['high' if c >= 0.5 else 'low' for c in completeness]

# Save precomputed file
df.to_csv(PRECOMPUTED_CSV, index=False)
print(f"SAVED {PRECOMPUTED_CSV} - {len(df)} products, {len(personas)*3} columns added!")
print("Columns: health_score_X, health_label_X, health_confidence_X for all personas")

import pandas as pd
import numpy as np
import json
from dataclasses import dataclass
from typing import List, Literal, Optional, Dict, Any
from openai import OpenAI
import os

# ============================================================================
# CONFIG
# ============================================================================
THESYS_API_KEY = "sk-th-ULhxYJFYke0nW9r5ka7cBh97pZxZ0MbxkHD0JtdKvyE7AGDxHUOuC7yM4ho5YroMFYjV37bIjAWpQzM4qHdfBbkmL8oM5DPOu1WB"
OPENROUTER_API_KEY = os.environ.get("OPENROUTER_API_KEY", "sk-or-v1-9def0c1a8c75e2b6d8f9e3a4c5b6d7e8f9a0b1c2d3e4f5a6b7c8d9e0f1a2b3c")

os.environ["THESYS_API_KEY"] = THESYS_API_KEY

# ============================================================================
# TYPES
# ============================================================================

Persona = Literal[
    "standard",
    "diabetic",
    "hypertension",
    "bodybuilder",
    "vegan",
    "vegetarian",
    "eggetarian",
    "jain",
    "pregnancy",
    "lactating",
    "elderly",
]

HealthLabel = Literal["green", "amber", "red"]

# ============================================================================
# HARDCODED REASONING (NO LLM NEEDED)
# ============================================================================

PERSONA_EXPLANATIONS: Dict[str, Dict[str, str]] = {
    "diabetic": {
        "red": "High sugar content causes rapid glucose spikes - dangerous for diabetics",
        "amber": "Moderate sugar/carbs - consume occasionally and monitor portions carefully",
        "green": "Low sugar, good fiber - helps maintain stable blood glucose levels",
    },
    "hypertension": {
        "red": "Dangerously high sodium - significantly raises blood pressure",
        "amber": "Moderate sodium content - limit portions to avoid blood pressure spikes",
        "green": "Low sodium, heart-healthy - supports healthy blood pressure management",
    },
    "bodybuilder": {
        "red": "Low protein, high sugar - counterproductive for muscle building goals",
        "amber": "Decent protein but not optimal - consider higher-protein alternatives",
        "green": "High protein, good macros - excellent for muscle growth and recovery",
    },
    "standard": {
        "red": "High in sugar/sodium/processing - not recommended for regular consumption",
        "amber": "Moderately healthy - okay occasionally as part of balanced diet",
        "green": "Nutritious and balanced - great choice for everyday eating",
    },
    "vegan": {
        "red": "Contains animal-derived ingredients - not suitable for a vegan diet",
        "amber": "Mostly plant-based but may contain minor animal-derived components",
        "green": "Fully plant-based and nutritionally supportive for a vegan lifestyle",
    },
    "vegetarian": {
        "red": "Contains meat or fish - not suitable for a vegetarian diet",
        "amber": "May contain egg or other borderline ingredients - consume as per preference",
        "green": "Fully vegetarian with a generally balanced nutrition profile",
    },
    "eggetarian": {
        "red": "Contains meat or fish beyond eggs - not suitable for an eggetarian diet",
        "amber": "Contains egg along with some less ideal nutritional aspects",
        "green": "Egg-based or vegetarian and fits well within an eggetarian pattern",
    },
    "jain": {
        "red": "Contains root vegetables or non-Jain ingredients - not Jain-compliant",
        "amber": "Partially Jain-compatible but may have borderline ingredients",
        "green": "Jain-compliant ingredients and suitable for a Jain lifestyle",
    },
    "pregnancy": {
        "red": "High in risky ingredients (excess sugar/sodium or questionable additives) for pregnancy",
        "amber": "Generally okay but best taken in moderation during pregnancy",
        "green": "Supports pregnancy needs with safer nutrient balance",
    },
    "lactating": {
        "red": "Poor nutrient profile or high in problematic ingredients for lactation",
        "amber": "Acceptable occasionally but not ideal as a regular choice while lactating",
        "green": "Supports lactation needs with better nutrient quality",
    },
    "elderly": {
        "red": "High in sugar/sodium or low in beneficial nutrients for elderly individuals",
        "amber": "Moderately suitable but should be limited for elderly",
        "green": "Gentle on health with supportive nutrients for elderly individuals",
    },
}

ALT_ADVANTAGES: Dict[str, str] = {
    "diabetic": "Lower sugar, higher fiber - better blood glucose control",
    "hypertension": "Lower sodium, healthier fats - supports heart health",
    "bodybuilder": "Higher protein content - better muscle-building potential",
    "standard": "Better overall nutrition - less sugar, more nutrients",
    "vegan": "More plant-based and nutrient-dense for a vegan lifestyle",
    "vegetarian": "Improved nutritional profile while staying fully vegetarian",
    "eggetarian": "Better macros and quality while fitting eggetarian choices",
    "jain": "More Jain-friendly ingredients with a better nutrient profile",
    "pregnancy": "Better aligned with pregnancy nutrition and safety considerations",
    "lactating": "More supportive of lactation nutrition and energy needs",
    "elderly": "Gentler, more balanced option for elderly health",
}

# ============================================================================
# DATACLASSES
# ============================================================================


@dataclass
class Product:
    product_id: int
    name: str
    brand: str
    category: str
    subcategory: str
    health_score: float
    health_label: HealthLabel
    health_confidence: str
    raw_row: Dict[str, Any]


@dataclass
class ScoredItem:
    product: Product
    persona: Persona
    explanation: str  # Why this label for this persona


@dataclass
class Alternative:
    original: ScoredItem
    replacement: Product
    advantage: str  # Why replacement is better
    improvement: str  # % or quality improvement


@dataclass
class CartReport:
    persona: Persona
    items: List[ScoredItem]
    alternatives: List[Alternative]
    swapped_cart: Optional[List[Product]]
    improvement_pct: Optional[int]
    swap_prompt: Optional[str]
    final_narrative: str


# ============================================================================
# FAST DATA LOADER (reads precomputed scores from CSV)
# ============================================================================


class FastLoader:
    def __init__(self, csv_path: str):
        # Accept absolute paths or paths relative to this module
        if not os.path.isabs(csv_path):
            csv_path = os.path.join(BASE_DIR, csv_path)

        print(f"[FastLoader] Loading {csv_path}...")
        if not Path(csv_path).exists():
            raise FileNotFoundError(f"Precomputed CSV not found: {csv_path}")
        self.df = pd.read_csv(csv_path)
        print(f"Loaded {len(self.df)} products in <2 sec")

    def get_products_for_persona(self, persona: Persona) -> List[Product]:
        """Load products with precomputed scores for this persona"""
        products: List[Product] = []

        score_col = f"health_score_{persona}"
        label_col = f"health_label_{persona}"
        conf_col = f"health_confidence_{persona}"

        for idx, row in self.df.iterrows():
            products.append(
                Product(
                    product_id=idx,
                    name=str(row.get("product_name_en", "")),
                    brand=str(row.get("brands", "")),
                    category=str(row.get("category", "Unknown")),
                    subcategory=str(row.get("subcategory", "Unknown")),
                    health_score=float(row.get(score_col, 0.0))
                    if pd.notna(row.get(score_col))
                    else 0.0,
                    health_label=str(row.get(label_col, "amber")).lower()
                    if pd.notna(row.get(label_col))
                    else "amber",
                    health_confidence=str(row.get(conf_col, "low")).lower()
                    if pd.notna(row.get(conf_col))
                    else "low",
                    raw_row=row.to_dict(),
                )
            )

        return products


# ============================================================================
# FAST MATCHER (simple fuzzy search - NO LLM)
# ============================================================================


class FastMatcher:
    def __init__(self, products: List[Product]):
        self.products = products
        self.name_index: Dict[str, Product] = {
            p.name.lower().strip(): p for p in products
        }

    def find_product(self, name: str) -> Optional[Product]:
        """Find product by name - fuzzy matching"""
        name_lower = name.lower().strip()

        # Exact match
        if name_lower in self.name_index:
            return self.name_index[name_lower]

        # Substring match
        for prod_name, product in self.name_index.items():
            if name_lower in prod_name or prod_name in name_lower:
                return product

        return None


# ============================================================================
# FAST SCORER (reads CSV, adds explanations - NO LLM)
# ============================================================================


class FastScorer:
    @staticmethod
    def score_item(product: Product, persona: Persona) -> ScoredItem:
        """Score already in CSV, just add explanation"""
        label = product.health_label
        explanations = PERSONA_EXPLANATIONS.get(
            persona, PERSONA_EXPLANATIONS["standard"]
        )
        explanation = explanations.get(label, "Nutrition evaluated")

        return ScoredItem(
            product=product,
            persona=persona,
            explanation=explanation,
        )


# ============================================================================
# FAST ALTERNATIVE FINDER (code logic - NO LLM)
# ============================================================================


class FastAlternativeFinder:
    def __init__(self, all_products: List[Product]):
        self.products = all_products
        # Index by subcategory
        self.by_subcat: Dict[str, List[Product]] = {}
        for p in all_products:
            if p.subcategory not in self.by_subcat:
                self.by_subcat[p.subcategory] = []
            self.by_subcat[p.subcategory].append(p)

    def find_alternative(self, scored: ScoredItem, persona: Persona) -> Optional[Alternative]:
        """Find GREEN alternative in same subcategory"""
        if scored.product.health_label == "green":
            return None  # Already optimal

        subcat = scored.product.subcategory
        if subcat not in self.by_subcat:
            return None

        # Find GREEN alternatives in same subcategory
        candidates = [
            p
            for p in self.by_subcat[subcat]
            if p.health_label == "green" and p.product_id != scored.product.product_id
        ]

        if not candidates:
            return None

        # Pick highest scoring GREEN
        best = max(candidates, key=lambda x: x.health_score)

        # Calculate improvement
        base = max(abs(scored.product.health_score), 0.1)
        improvement_pct = int(((best.health_score - scored.product.health_score) / base) * 100)
        improvement_pct = max(0, min(100, improvement_pct))

        advantage = ALT_ADVANTAGES.get(persona, "Better nutritional profile")

        return Alternative(
            original=scored,
            replacement=best,
            advantage=advantage,
            improvement=f"+{improvement_pct}% health score improvement",
        )


# ============================================================================
# LLM INTERFACE (ONLY for final integrated narrative)
# ============================================================================


class LLMNarrative:
    def __init__(
        self,
        api_key: str = THESYS_API_KEY,
        model: str = "claude-3-5-sonnet-20241022",
    ):
        """
        LLM client with Thesys primary and fallback support
        """
        self.thesys_api_key = api_key
        self.thesys_model = model
        self.openrouter_api_key = OPENROUTER_API_KEY
        self.thesys_client = None
        self.client_type = None
        
        # Try Thesys first
        try:
            self.thesys_client = OpenAI(
                base_url="https://api.thesys.dev",
                api_key=api_key,
                default_headers={
                    "HTTP-Referer": "https://b4ubuy.app",
                    "X-Title": "B4UBuy Nutrition Analyzer"
                }
            )
            self.client_type = "thesys"
            print(f"LLM ready (Thesys | model={model})")
        except Exception as e:
            print(f"Thesys initialization: {e}")
            # Thesys failed, will use OpenRouter
            self.client_type = "fallback"
            print("Will use OpenRouter fallback for LLM")

    def generate_narrative(self, report_data: Dict) -> str:
        """Generate narrative, with fallback handling"""
        persona = report_data.get("persona", "standard")

        system_msg = (
            "You are a deterministic nutrition-report generation engine.\n"
            "Your ONLY job is to convert provided structured data into a formatted report.\n\n"

            "STRICT CONSTRAINTS (MUST FOLLOW):\n"
            "1. Treat the provided DATA as ground truth. NEVER recompute, infer, estimate, or add new facts.\n"
            "2. Do NOT introduce any nutrition advice, warnings, medical disclaimers, or external knowledge.\n"
            "3. Every product in the DATA must be mentioned exactly once, using its assigned emoji:\n"
            "   ğŸŸ¢ = recommended, ğŸŸ  = acceptable, ğŸ”´ = avoid.\n"
            "4. Use explanations exactly as provided in the DATA. Do not paraphrase them.\n"
            "5. If alternatives are present, mention them explicitly; if not, do not invent any.\n"
            "6. Maintain the original product order as given in the DATA.\n"
            "7. Persona affects tone only, never facts.\n"
            "8. FORMAT: List items as BULLET POINTS. Alternatives and improvement summary NOT as bullet points.\n"
            "9. Bold important values using **text** markdown: percentages, improvement amounts, scores.\n"
            "10. End with a question about swapping items (not a bullet point).\n"
            "11. Keep each item bullet point concise (under 15 words).\n\n"

            "FAILURE CONDITIONS (AVOID):\n"
            "- Adding or removing products\n"
            "- Rewriting explanations\n"
            "- Creating bullet points for alternatives and improvement summary\n"
            "- Referencing scores, numbers, or internal reasoning without bold formatting\n"
        )

        user_msg = f"""
Persona: {persona}

DATA (already computed by code, do NOT recalculate):
{json.dumps(report_data, indent=2)}

Requirements:
- Format items as BULLET POINTS, one per line starting with â€¢
- List each item with its emoji (ğŸŸ¢ğŸŸ ğŸ”´) and explanation
- Bold all percentages and improvement amounts: **+96%**, **100% improvement**
- List healthier alternatives as REGULAR TEXT (NOT bullets)
- Swapping summary as REGULAR TEXT (NOT bullets)
- End with a yes/no question (NOT a bullet point)
- Each item bullet under 15 words
- Use markdown bold (**text**) for emphasis
"""

        try:
            # Try Thesys first
            if self.thesys_client:
                try:
                    response = self.thesys_client.chat.completions.create(
                        model=self.thesys_model,
                        messages=[
                            {"role": "system", "content": system_msg},
                            {"role": "user", "content": user_msg},
                        ],
                        max_tokens=800,
                        temperature=0.7,
                    )
                    return response.choices[0].message.content
                except Exception as thesys_error:
                    print(f"\nâŒ Error calling Thesys API: {thesys_error}")
                    print("Trying OpenRouter fallback...\n")

            # Fallback to OpenRouter
            openrouter_client = OpenAI(
                base_url="https://openrouter.ai/api/v1",
                api_key=self.openrouter_api_key,
                default_headers={
                    "HTTP-Referer": "https://b4ubuy.app",
                    "X-Title": "B4UBuy Nutrition Analyzer"
                }
            )
            
            response = openrouter_client.chat.completions.create(
                model="anthropic/claude-3.5-sonnet",
                messages=[
                    {"role": "system", "content": system_msg},
                    {"role": "user", "content": user_msg},
                ],
                max_tokens=800,
                temperature=0.7,
            )
            print("âœ“ OpenRouter fallback successful\n")
            return response.choices[0].message.content

        except Exception as e:
            print(f"\nâŒ Error calling all LLM APIs: {e}")
            print("Generating fallback narrative...\n")
            return self._generate_fallback_narrative(report_data)

    def _generate_fallback_narrative(self, report_data: Dict) -> str:
        """Generate a bullet-point formatted report if API fails"""
        persona = report_data.get("persona", "standard")
        items = report_data.get("items", [])
        alternatives = report_data.get("alternatives", [])
        improvement_pct = report_data.get("improvement_percentage", 0)

        narrative = f"Shopping Cart Analysis for {persona.upper()} Persona:\n\n"

        # List all items with emojis and explanations (as bullet points)
        for item in items:
            emoji_map = {"green": "ğŸŸ¢", "amber": "ğŸŸ ", "red": "ğŸ”´"}
            emoji = emoji_map.get(item['label'], "ğŸŸ ")
            narrative += f"â€¢ {emoji} {item['name']}: {item['explanation']}\n"

        # Add alternatives section (NOT as bullet points)
        if alternatives:
            narrative += f"\nHealthier Alternatives Found:\n"
            for alt in alternatives:
                narrative += f"Replace {alt['original']} with {alt['replacement']} - {alt['advantage']} (**{alt['improvement']} improvement**)\n"

            narrative += f"\nSwapping these alternatives will improve your cart by approximately **{improvement_pct}%** for {persona} health goals.\n"
            narrative += "\nWould you like to apply these healthier swaps to your cart?"
        else:
            narrative += f"\nâ€¢ Your cart looks great for {persona} persona! All items are already optimal choices."

        return narrative






# ============================================================================
# MAIN ENGINE (ULTRA FAST)
# ============================================================================


class FastEngine:
    def __init__(self, csv_path: str = "openfoodfacts_precomputed.csv"):
        print("\n" + "=" * 80)
        print("B4UBuy ULTRA-FAST ENGINE")
        print("=" * 80)
        self.loader = FastLoader(csv_path)

        # Initialize with Thesys C1 or OpenRouter
        self.llm = LLMNarrative(api_key=THESYS_API_KEY)


        print("System ready - analysis will take ~5-10 seconds")
        print("=" * 80 + "\n")


    def analyze_cart(self, item_names: List[str], persona: Persona = "diabetic") -> CartReport:
        print(f"\nğŸ›’ Analyzing cart for {persona} persona...")
        print(f"Items: {', '.join(item_names)}\n")

        # STEP 1: Load products with precomputed scores (FAST - no LLM)
        print("STEP 1: Loading precomputed scores from CSV...")
        all_products = self.loader.get_products_for_persona(persona)

        matcher = FastMatcher(all_products)

        # STEP 2: Match items (FAST - simple string matching)
        print("STEP 2: Matching products...")
        matched: List[Product] = []
        for name in item_names:
            product = matcher.find_product(name)
            if product:
                matched.append(product)
                emoji = (
                    "ğŸŸ¢"
                    if product.health_label == "green"
                    else "ğŸŸ "
                    if product.health_label == "amber"
                    else "ğŸ”´"
                )
                print(f" {emoji} {product.name} - {product.health_label.upper()}")

        # STEP 3: Score items (FAST - just read from CSV + add explanation)
        print("STEP 3: Adding explanations...")
        scorer = FastScorer()
        scored_items: List[ScoredItem] = [
            scorer.score_item(p, persona) for p in matched
        ]

        # STEP 4: Find alternatives (FAST - code logic only)
        print("STEP 4: Finding alternatives...")
        alt_finder = FastAlternativeFinder(all_products)
        alternatives: List[Alternative] = []

        for scored in scored_items:
            if scored.product.health_label in ["red", "amber"]:
                alt = alt_finder.find_alternative(scored, persona)
                if alt:
                    alternatives.append(alt)
                    print(
                        f" -> {alt.original.product.name} -> {alt.replacement.name} ({alt.improvement})"
                    )

        # STEP 5: Calculate swapped cart and improvement
        print("STEP 5: Calculating improvement...")
        swapped_cart: Optional[List[Product]] = None
        improvement_pct: Optional[int] = None
        swap_prompt: Optional[str] = None

        if alternatives:
            # Build swapped cart
            alt_map = {
                alt.original.product.product_id: alt.replacement
                for alt in alternatives
            }
            swapped_cart = []
            for scored in scored_items:
                if scored.product.product_id in alt_map:
                    swapped_cart.append(alt_map[scored.product.product_id])
                else:
                    swapped_cart.append(scored.product)

            # Calculate improvement %
            avg_before = np.mean([s.product.health_score for s in scored_items])
            avg_after = np.mean([p.health_score for p in swapped_cart])
            base = max(abs(avg_before), 0.1)
            improvement_pct = int(((avg_after - avg_before) / base) * 100)
            improvement_pct = max(0, min(100, improvement_pct))

            # Generate swap prompt (kept for CLI-style display if needed)
            green_count_before = sum(
                1 for s in scored_items if s.product.health_label == "green"
            )
            green_count_after = sum(
                1 for p in swapped_cart if p.health_label == "green"
            )

            swap_prompt = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ ğŸ”„ PROPOSED SWAPPED CART                                         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
"""
            for i, product in enumerate(swapped_cart, 1):
                emoji = (
                    "ğŸŸ¢"
                    if product.health_label == "green"
                    else "ğŸŸ "
                    if product.health_label == "amber"
                    else "ğŸ”´"
                )
                swap_prompt += f"â•‘ {i}. {emoji} {product.name[:50]:<50} â•‘\n"

            swap_prompt += f"""â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ ğŸ“Š IMPROVEMENT ANALYSIS                                         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ â€¢ Cart will improve by {improvement_pct}% if you swap           â•‘
â•‘ â€¢ GREEN items: {green_count_before} â†’ {green_count_after}                     â•‘
â•‘ â€¢ Your cart will be {improvement_pct}% healthier for {persona}  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ â“ Would you like to apply these swaps? (y/n)                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

        # STEP 6: LLM generates final integrated narrative (ONLY LLM CALL)
        print("STEP 6: Generating integrated narrative with LLM...")

        report_data: Dict[str, Any] = {
            "persona": persona,
            "items": [
                {
                    "name": s.product.name,
                    "label": s.product.health_label,
                    "category": s.product.subcategory,
                    "explanation": s.explanation,
                    "score": s.product.health_score,
                }
                for s in scored_items
            ],
            "alternatives": [
                {
                    "original": alt.original.product.name,
                    "replacement": alt.replacement.name,
                    "advantage": alt.advantage,
                    "improvement": alt.improvement,
                }
                for alt in alternatives
            ],
            "improvement_percentage": improvement_pct,
            "green_count": sum(
                1 for s in scored_items if s.product.health_label == "green"
            ),
            "amber_count": sum(
                1 for s in scored_items if s.product.health_label == "amber"
            ),
            "red_count": sum(
                1 for s in scored_items if s.product.health_label == "red"
            ),
        }

        narrative = self.llm.generate_narrative(report_data)

        print("Analysis complete!\n")

        return CartReport(
            persona=persona,
            items=scored_items,
            alternatives=alternatives,
            swapped_cart=swapped_cart,
            improvement_pct=improvement_pct,
            swap_prompt=swap_prompt,
            final_narrative=narrative,
        )


# ============================================================================
# MAIN
# ============================================================================

if __name__ == "__main__":
    # Initialize engine with Thesys C1
    engine = FastEngine(
        csv_path="openfoodfacts_precomputed.csv"
    )

    # Analyze cart (5-10 seconds)
    items = ["salted peanuts", "Bansi Rava", "choki choki chocolate milk"]
    report = engine.analyze_cart(items, persona="hypertension")

    # Display a SINGLE integrated report (no separate summary section)
    print("\n" + "=" * 80)
    print("ğŸ“‹ INTEGRATED NUTRITION REPORT")
    print("=" * 80)

    # Show structured view (if you still want the CLI-style breakdown)
    print("\nğŸ“¦ STRUCTURED CART VIEW (for debugging/CLI):")
    for scored in report.items:
        emoji = (
            "ğŸŸ¢"
            if scored.product.health_label == "green"
            else "ğŸŸ "
            if scored.product.health_label == "amber"
            else "ğŸ”´"
        )
        print(f"\n{emoji} {scored.product.name}")
        print(f" Status: {scored.product.health_label.upper()}")
        print(f" Why (rule-based): {scored.explanation}")

    if report.alternatives:
        print("\n\nğŸ’¡ HEALTHIER ALTERNATIVES (rule-based):")
        for alt in report.alternatives:
            print(f"\nâŒ {alt.original.product.name} ({alt.original.product.subcategory})")
            print(f"{alt.replacement.name} ({alt.replacement.subcategory})")
            print(f" Advantage: {alt.advantage}")
            print(f" Impact: {alt.improvement}")

    if report.swap_prompt:
        print("\n" + report.swap_prompt)

    # Now print the SINGLE integrated AI narrative which folds in what used to be
    # the 'final report' and 'AI nutritionist summary' into one.
    print("\n" + "=" * 80)
    print("ğŸ¤– INTEGRATED AI NUTRITIONIST NARRATIVE")
    print("=" * 80)
    print(report.final_narrative)
    print("\n" + "=" * 80)

